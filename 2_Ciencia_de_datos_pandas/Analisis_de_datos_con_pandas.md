> Este material retoma material de [Bioinfo UNQ](https://github.com/AJVelezRueda/Bioinfo_UNQ/tree/master/Trabajos_Practicos/Estadistica_con_pandas) y [Python_for_friends](https://github.com/jennifergc/Python_for_friends/tree/Angie)


### IntroducciÃ³n a la Ciencia de Datos con Python

Para este recorrido necesitarÃ¡s las librerÃ­as [Pandas](https://pandas.pydata.org/), [Seaborn](https://seaborn.pydata.org/) y [Scipy](https://www.scipy.org/)


Podes corroborar si las tienes instaladas corriendo las siguientes lÃ­neas en tu intÃ©rprete de Python:

```python
import pandas as pd
import seaborn as sns
import scipy.stats as ss
```

Si correr estas lineas no tira ningÃºn error, etonces estÃ¡n felizmente instaladas las bibliotecas enc uestiÃ³n. De lo contrario, obtendremos un mensaje de error `ModuleNotFoundError: No module named` al correr las lineas anteriores. En tal caso, podÃ©s instalar las bibliotecas desde la consola, con el comando:

```bash
        pip install pandas
        pip install seaborn
        pip install scipy
```

En este recorrido trabajaremos sobre los datos abiertos del sobre el personal del [Ministerio de Ciencia y TecnologÃ­a](https://datasets.datos.mincyt.gob.ar/dataset/personal-de-ciencia-y-tecnologia/archivo/11dca5bb-9a5f-4da5-b040-28957126be18) del Gobierno Argentino. 

Si bien no es estrictamente necesario saber a fondo la sintaxis de Python para comenzar a utilizar Pandas, te recomendamos fuertemente realizar el [recorrido introductorio de Python](https://github.com/AJVelezRueda/UCEMA_Fundamentos_de_informatica/blob/master/Python_intro/intro_python_tutorial.md), que te brindarÃ¡ los conocimientos bÃ¡sicos de programaciÃ³n en general y de Python particular que te permitiran abordar este contenido sin problemas.

# Guias de Trabajo
 * [1. Carga e inspecciÃ³n de datos](#1-carga)
 * [2. Tratamiento de datos faltantes](#2-faltantes)


[1. Tratamiento de Datos con Python](#1-carga)

El primer paso para poder analizar los datos y sacar conclusiones de ese anÃ¡lisis es realizar una
limpieza de los mismos... Â¡claro que no vamos a pasarle el plumero para sacarle el polvo! Limpieza de datos se refiere por ejemplo a verificar si faltan datos o si a alguna de las columnas debe hacerseles una correcciÃ³n de notaciÃ³n o de tipo de dato, etc.

Para ello vamos a recurrir a alguno de los mÃ©todos que vimos en la [guÃ­a introductoria](https://github.com/flbulgarelli/recursos-python/blob/master/2_Ciencia_de_datos_pandas/Introducci%C3%B3n_pandas.md). Para comenzar descargaremos localmente la [tabla](https://datasets.datos.mincyt.gob.ar/dataset/personal-de-ciencia-y-tecnologia/archivo/11dca5bb-9a5f-4da5-b040-28957126be18) de personas que conforman el Ministerio de Ciencia y TecnologÃ­a de Argentina, en formato csv. Podemos cargar (leer) la el contenido del archivo en un DataFrame de Pandas de nombre `personas`

```python
import pandas as pd
personas =  pd.read_csv("personas_2011_cyt.csv", sep=";")
personas.head()
```

> Para pensar ðŸ¤”: Al imprimir el DataFrame se ven celdas con valores `NaN` Â¿QuÃ© son esos valores?Â¿QuÃ© significa? Â¿A quÃ© columna corresponden estos valores? Â¿QuÃ© tipo de datos son los pertenecientas a cada una de las columnas (categÃ³ricos o numÃ©ricos)?

Podemos obtener la informaciÃ³n general del DataFrame haciendo:


```python
personas.info()
```

<details>
  <summary>Resultado</summary>

```python
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 68552 entries, 0 to 68551
Data columns (total 21 columns):
 #   Column                                Non-Null Count  Dtype  
---  ------                                --------------  -----  
 0   persona_id                            68552 non-null  int64  
 1   anio                                  68552 non-null  int64  
 2   sexo_id                               68552 non-null  int64  
 3   edad                                  68552 non-null  int64  
 4   maximo_grado_academico_id             68552 non-null  int64  
 5   disciplina_maximo_grado_academico_id  68552 non-null  int64  
 6   disciplina_titulo_grado_id            68552 non-null  int64  
 7   disciplina_experticia_id              68552 non-null  int64  
 8   tipo_personal_id                      68552 non-null  int64  
 9   producciones_ult_anio                 68552 non-null  int64  
 10  producciones_ult_2_anios              68552 non-null  int64  
 11  producciones_ult_3_anios              68552 non-null  int64  
 12  producciones_ult_4_anios              68552 non-null  int64  
 13  institucion_trabajo_id                68552 non-null  int64  
 14  seniority_level                       68552 non-null  object 
 15  categoria_conicet_id                  48640 non-null  float64
 16  categoria_incentivos                  48640 non-null  float64
 17  max_dedicacion_horaria_docente_id     48640 non-null  float64
 18  institucion_cargo_docente_id          48640 non-null  float64
 19  clase_cargo_docente_id                48640 non-null  float64
 20  tipo_condicion_docente_id             48640 non-null  float64
dtypes: float64(6), int64(14), object(1)
memory usage: 11.0+ MB
```
</details>

Como verÃ¡s esta es una descripciÃ³n genÃ©rica de nuestro DataFrame, de la cuÃ¡l podemos obtener el nombre de cada columna (variable), el tipo de datos correspondiente a cada una de ellas, y cuÃ¡ntas filas por columna poseen informaciÃ³n.

Sin embargo, el anÃ¡lisis de los datos implica hacernos preguntas sobre la informaciÃ³n que estos contienen e intentar encontrar respuestas, dentro de lo posible que sean generalizables. AquÃ­ es donde entra en juego ðŸ¥...Â¡Si: La estadÃ­stica!

Podemos hacer un primer anÃ¡lisis estadÃ­stico bÃ¡sico de nuestro conjunto de datos utilizando el mÃ©todo `describe()`:

```python
personas.describe()
```

> Para pensar ðŸ¤”: Â¿QuÃ© datos nos devuelve el mÃ©todo `describe()`? Â¿QuÃ© significan estos valores?Â¿Son Ãºtiles para todas las columnas?

De la inspecciÃ³n general de los datos y su anÃ¡lisis estadÃ­stico bÃ¡sico podemos decir, por ejemplo, que el promedio de edades es de 38 aÃ±os Â¿Pero podemos decir que el promedio de maximo_grado_academico_id es 3? Bueno, es claro que el mÃ¡ximo grado acadÃ©mico habla de cual es el nivel mÃ¡s alto de estudios que logrÃ³ cada persona (primario, secundario, universitario, etc) por lo que 3 no tiene ningÃºn sentido en este caso. Pero aÃºn reemplazando las palabras correspondientes a cada identificador, un promedio no tiene sentido alguno para esta variable. 

Sin embargo, nos puede interesar saber cuÃ¡l es el grado de formaciÃ³n que tiene el personal Â¿Son mayormente universitarixs? Â¿mayormente terminaron el secundario? Para ello podemos calcular la frecuencia de apariciÃ³n de cada una de estas categorÃ­as/datos. Esto es contar cuÃ¡ntas veces del total de filas aparece cada una de ellas:

```python
personas['maximo_grado_academico_id'].value_counts()
```

[2. Tratamiento de datos faltantes](#2-faltantes)
No hace falta suspicacia para prever que en esta secciÃ³n hablaremos de los datos faltantes. Como hemos visto nuestra tabla, muestra celdas si informaciÃ³n. Y ya hemos visto por medio del mÃ©todo info() cuÃ¡ntos valores no nulos posee cada columna. Haro nos vamos a enfocar en el vaso medio vacÃ­o, probemos el siguiente cÃ³digo:

```python
personas.isnull().sum()
```

<details>
  <summary>Resultado</summary>

```python
persona_id                                  0
anio                                        0
sexo_id                                     0
edad                                        0
maximo_grado_academico_id                   0
disciplina_maximo_grado_academico_id        0
disciplina_titulo_grado_id                  0
disciplina_experticia_id                    0
tipo_personal_id                            0
producciones_ult_anio                       0
producciones_ult_2_anios                    0
producciones_ult_3_anios                    0
producciones_ult_4_anios                    0
institucion_trabajo_id                      0
seniority_level                             0
categoria_conicet_id                    19912
categoria_incentivos                    19912
max_dedicacion_horaria_docente_id       19912
institucion_cargo_docente_id            19912
clase_cargo_docente_id                  19912
tipo_condicion_docente_id               19912
dtype: int64
```
</details>



>
> Para pensar ðŸ¤”: Â¿CuÃ¡les son las columnas con valores nulos? Â¿Coinciden con las que tenÃ­an valores `NaN`?Â¿QuÃ© obtenemos cuÃ¡ndo hacemos `isnull()`?
>


Los datos faltantes pueden alterar el anÃ¡lisis de datos ya que disminuyen el tamaÃ±o de las muestras y, por tanto, la potencia de los tests estadÃ­sticos. Por ello, resulta necesario hacer un tratamiento de los datos faltantes, previo al anÃ¡lisis de los datos. Existen distintos modos de trabajar con los datos faltantes, dependiendo mayormente de nuestro lote de datos y de la variable en cuestiÃ³n. 

> Antes de tomar cualquier decisiÃ³n, cabe preguntarse algunas cosas:
>  ðŸ§—â€â™€ï¸ DesafÃ­o I: Calcular el porcentaje del total de datos, representan los datos nulos de cada columna (variable)
> Para pensar ðŸ¤”: Â¿QuÃ© informaciÃ³n me aporta cada una de las columnas con datos faltantes? Â¿QuÃ© tipo de datos son los pertenecientas a cada una de las columnas (categÃ³ricos o numÃ©ricos)?Â¿Es relevante dicha variable para el anÃ¡lisis global de los datos? 