> Este material se basa en [Clustering con Python by JoaquÃ­n Amat Rodrigo](https://www.cienciadedatos.net/documentos/py20-clustering-con-python.html) 

# Pasos previos
Para este recorrido necesitarÃ¡s las librerÃ­as [Pandas](https://pandas.pydata.org/), [Seaborn](https://seaborn.pydata.org/) y [Scipy](https://www.scipy.org/)

Podes corroborar si las tienes instaladas corriendo las siguientes lÃ­neas en tu intÃ©rprete de Python:

```python
import pandas as pd
import seaborn as sns
import scipy.stats as ss
```

Si correr estas lineas no tira ningÃºn error, etonces estÃ¡n felizmente instaladas las bibliotecas enc uestiÃ³n. De lo contrario, obtendremos un mensaje de error `ModuleNotFoundError: No module named` al correr las lineas anteriores. En tal caso, podÃ©s instalar las bibliotecas desde la consola, con el comando:

```bash
        pip install pandas
        pip install seaborn
        pip install scipy
```


# Guias de Trabajo
 * [1.Clustering Â¿QuÃ© es?](#1-Intro)
 * [2.Un ojo en el Iris](#1-Iris)
 * [3.Calculo de distancias](#3-distancia)
 * [4.K-means](#4-kmeans)
 * [5.Agrupamiento jerÃ¡rquico](#5-agrupamiento)

[1.Clustering Â¿QuÃ© es?](#1-Intro)
Hemos estado trabajando hasta aquÃ­ en la carga y limpieza da datos con Pandas. Es momento de comenzar a trabajar con los datos, analizarlos y poder encontrar patrones que nos permitan derivar informaciÃ³n. El aprendizaje automÃ¡tico consiste en identificar de patrones o tendencias que de los datos de forma automÃ¡tica.

> Para pensar ğŸ¤”: Â¿QuÃ© utilidad le encontrÃ¡s al aprendizaje automatizado? Â¿QuÃ© aplicaciones se te ocurren o conoces?


<details>
  <summary>Recurso audiovisuales complementarios</summary>

[Inteligencia Artificial: Â¿Amiga o Enemiga? | Diego FernÃ¡ndez Slezak](https://www.youtube.com/watch?v=znq3ql6wqnE)

[Â¿De quÃ© es capaz la inteligencia artificial? | DW Documental](https://www.youtube.com/watch?v=34Kz-PP_X7c&t=146s)
</details>

En este recorrido nos centraremos particularmente en mÃ©todos que nos permitan describir la estructura u organizaciÃ³n de nuestros datos. Los mÃ©todos de clustering(agrupamientos) nos permiten buscar patrones "ocultos" en los datos sin la necesidad de contar con la informaciÃ³n sobre la verdadera clasificaciÃ³n (etiquetas) de los datos. Son mÃ©todos exploratorios que agrupan los datos segÃºn similitud para simplificar su anÃ¡lisis.

> Para pensar ğŸ¤”: Â¿QuÃ© tipo de simplificaciones permite el agrupamiento de datos?

Existen una amplia cantidad de tÃ©cnicas que nos permiten encontrar patrones en los datos y agruparlas de algÃºn modo, pero en todos los casos estos agrupamientos se establecen de forma que, las observaciones que estÃ¡n dentro de un mismo grupo, son similares entre ellas y distintas a las de otros grupos. Todos los mÃ©todos de clustering requieren de la definiciÃ³n y cuantificaciÃ³n de la similitud entre las observaciones. Es por ello que resulta necesario revisar el concepto de distancia, ya que es lo que se usa como medida de similitud o diferencia entre grupos.



[2.Un ojo en el Iris](#2-Iris)


En este recorrido utilizaremos el [set de datos](https://github.com/flbulgarelli/recursos-python/blob/master/2_Ciencia_de_datos_pandas/iris_data.txt) [Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set) que consiste en un conjunto de datos u observaciones realizadas por el biÃ³logo Ronald Fisher, sobre las caracterÃ­stica de distintas especies de plantas plantas. Â¿SerÃ¡ posible clasificar las plantas utilizando alguno de estas observaciones que hizo Fisher?

Vamos a explorar los datos:

```python
import pandas as pd

iris = pd.read_csv(datapath + "iris/iris_hidden.txt", sep = '\t')
```


>  ğŸ§—â€â™€ï¸ DesafÃ­o I: AveriguÃ¡ quÃ© variables (columnas) tiene la tabla e inspecionÃ¡ el DataFrame

Para tener una idea mÃ¡s intuitiva del "comportamiento" de los datos podemos graficar la distribuciÃ³n de frecuencias de las distintas variables que nos permitirÃ¡, por ejemplo,  saber si las observaciones son Ãºnicas o se repiten. Para ello utilizaremos la biblioteca [Seaborn](https://seaborn.pydata.org/):

```python
import seaborn as sns

g = sns.histplot(data = iris, x = "sepal.length", binwidth=0.25, kde = True)

```


> Para pensar ğŸ¤”: Â¿QuÃ© informaciÃ³n obtenes del grÃ¡fico? 
> ğŸ§—â€â™€ï¸ DesafÃ­o II: Grafica la distribuciÃ³n de frecuencias de la variable "petal.length" Â¿QuÃ© informaciÃ³n obtenes del grÃ¡fico? Â¿QuÃ© diferencias notÃ¡s respecto del observado para la variable sepal.length? 
> ğŸ§—â€â™€ï¸ DesafÃ­o III: Grafica la distribuciÃ³n de frecuencias del resto de las variables.
> Para pensar ğŸ¤”: Â¿QuÃ© informaciÃ³n pudiste obtener de observar las distribuciones de las distintas variables? Â¿CuÃ¡ntos tipos de plantas crees que existen?

Ahora que pudimos observar como se comportan las variables, nos puede ser de gran utilidad estudiar las asociaciones entre las mismas (correlaciÃ³n). De este modo sabremos si el comportamiento (crecimiento o disminuciÃ³n) de una variable, se debe o estÃ¡ influenciada por otra. Con los pairplots de seabron, podemos entonces estudiar si existen correlaciones entre las variables:


```python
import seaborn as sns

g = sns.pairplot(iris)

```
> ğŸ§—â€â™€ï¸ DesafÃ­o IV: Â¿Existe alguna correlaciÃ³n entre algunas de las variables? Â¿CÃ³mo te diste cuenta? 


[3.Calculo de distancias](#3-distancia)

Hemos observado las distribuciones de nuestros datos y la manera en que se correlacionan las variables, y de este modo comenzar a intuir posibles agrupamientos de los datos. Es decir, pudimos observar mediante grÃ¡ficos exploratorios que algunos registros muestran una mayor similitud entre si.

Justamente, los mÃ©todos de clustering permiten la identificaciÃ³n automÃ¡tica de grupos en los que se pueden agrupar las observaciones de un conjunto de datos. Esto se hace de forma tal que las observaciones o registros asignados a un mismo grupo, muestren una mayor similitud entre sÃ­ que con los miembros de otros grupos. Pero, Â¿CÃ³mo medimos similitud entre miembros de un grupo dado? ğŸ¤”

Una forma de obtener la similitud es asumir que los datos son puntos en el espacio, por lo que si se define la distancia ente los puntos y se mide la separaciÃ³n entre dos registros, podrÃ¡ obtenerse la similitud entre estos. 

Una de las formas mÃ¡s bÃ¡sicas para calcular la distancia  entre dos puntos es la EuclÃ­dea, basada en el famoso [Teorema de PitÃ¡goras](https://es.wikipedia.org/wiki/Teorema_de_Pit%C3%A1goras).. Â¡Si, era importante PitÃ¡goras!

![Distancia Euclidea](./dist_euclÃ­dea.gif)


Â¿Pero no todas las definiciones de distancia son aplicables a todos los tipos de datos no? Â¡Claro que no! Â¿Como por ejemplo...?

