> Este material retoma material de [Bioinfo UNQ](https://github.com/AJVelezRueda/Bioinfo_UNQ/tree/master/Trabajos_Practicos/Estadistica_con_pandas)

### IntroducciÃ³n a la Ciencia de Datos con Python

Para este recorrido necesitarÃ¡s las librerÃ­as [Pandas](https://pandas.pydata.org/), [Seaborn](https://seaborn.pydata.org/) y [Scipy](https://www.scipy.org/)


Podes corroborar si las tienes instaladas corriendo las siguientes lÃ­neas en tu intÃ©rprete de Python:

```python
import pandas as pd
import seaborn as sns
import scipy.stats as ss
```

Si correr estas lineas no tira ningÃºn error, etonces estÃ¡n felizmente instaladas las bibliotecas enc uestiÃ³n. De lo contrario, obtendremos un mensaje de error `ModuleNotFoundError: No module named` al correr las lineas anteriores. En tal caso, podÃ©s instalar las bibliotecas desde la consola, con el comando:

```bash
        pip install pandas
        pip install seaborn
        pip install scipy
```

En este recorrido trabajaremos sobre los datos abiertos del sobre el personal del [Ministerio de Ciencia y TecnologÃ­a](https://datasets.datos.mincyt.gob.ar/dataset/personal-de-ciencia-y-tecnologia/archivo/11dca5bb-9a5f-4da5-b040-28957126be18) del Gobierno Argentino. 

Si bien no es estrictamente necesario saber a fondo la sintaxis de Python para comenzar a utilizar Pandas, te recomendamos fuertemente realizar el [recorrido introductorio de Python](https://github.com/AJVelezRueda/UCEMA_Fundamentos_de_informatica/blob/master/Python_intro/intro_python_tutorial.md), que te brindarÃ¡ los conocimientos bÃ¡sicos de programaciÃ³n en general y de Python particular que te permitiran abordar este contenido sin problemas.

# Guias de Trabajo
  * [1. Un osito cariÃ±osito](#1-pandas)
  * [2. Trabajando con DataFrames](#2-dfs)
  * [3. MÃ©todos de los DataFrames](#3-metodos)
  * [4. Tratamiento de Datos con Python](#4-datos)

[1. Un osito cariÃ±osito](#1-pandas) 

En este recorrido vamos a adentrarnos en el mundo de los datos, y para ello utilizaremos Pandas, una biblioteca de Python que nos permite trabajar con archivos de formato definido: CSV, un excel, etc. AdemÃ¡s, Pandas proporciona estructuras de datos rÃ¡pidas, flexibles y expresivas diseÃ±adas para que trabajar con datos "relacionales" o "etiquetados" sea fÃ¡cil e intuitivo. En criollo: Pandas es como en excel, pero super duper!

> Para pensar ğŸ¤”: Si hasta aquÃ­ no te has preguntado quÃ© es una bliblioteca, Â¡es momento de hacerse esa pregunta! Â¿Para quÃ© creÃ©s que nos puede resultar Ãºtil esta biblioteca? Â¿CuÃ¡l es la ventaja de usar Pandas? Â¿Por quÃ© no solo usar Python `"de a pie"`?
>

Pandas soporta mÃºltipes tipos de datos:

- Datos tabulares con columnas de tipo heterogÃ©neo, como en una tabla SQL o en una hoja de cÃ¡lculo de Excel
- Datos ordenados y desordenados (no necesariamente frecuencia fija).
- Datos matriciales arbitrarios (homogÃ©neamente tipados o heterogÃ©neos) con etiquetas de fila y columna
- Cualquier otra forma de conjuntos de datos observacionales/estadÃ­sticos. 

Los datos en realidad no necesitan ser etiquetados para ser colocados en una estructura de datos de pandas. Estas estructuras se construyen a partir de arrays(listas), pero agregando nuevas funcionalidades. Pandas maneja dos estructuras de datos: Series y DataFrames.

**Series (1-dimensional)**
Las series pueden contener cualquier tipo de datos (enteros, cadenas, nÃºmeros de punto flotante, etc.). Y se pueden crear del siguiente modo:

```python
import pandas as pd
una_serie = pd.Series(['Peru', 'Argentina', 'Bolivia', 'Uruguay', 'Brasil', 'Chile'], dtype='string')

print(una_serie)
```

**DataFrames (2-dimensional)**

Un DataFrame es una estructura tabular bidimensional de datos tabulares, potencialmente heterogÃ©neos, con ejes etiquetados (filas y columnas). Las operaciones aritmÃ©ticas se alinean en las etiquetas de fila y columna. Se puede considerar como un contenedor similar a un dict para objetos Serie. Podemos crear un DataFrame del sigueinte modo:

```python
paises_latam = pd.DataFrame(data ={"Pais": ['Peru', 'Argentina', 'Bolivia', 'Uruguay', 'Brasil', 'Chile'], "Lengua oficial primaria": ['EspaÃ±ol', 'EspaÃ±ol', 'EspaÃ±ol', 'EspaÃ±ol', 'Portugues', 'EspaÃ±ol']}, index = [1,2,3,4,5,6])

print(paises_latam)
```

Por lo tanto, la serie es la estructura de datos para una sola columna de un DataFrame, no solo conceptualmente, sino literalmente, es decir, los datos en un DataFrame se almacenan realmente en la memoria como una colecciÃ³n de Series.

TambiÃ©n, se puede crear un DataFrame a partir de un diccionario, en este caso las claves se corresponderÃ¡n con los nombres de las columnas y los valores con los datos de las filas para cada columna:

```python
#serÃ¡ DataFrame(data=diccionario, index=filas, columns=columnas, dtype=tipos)
datos = {"Pais": ['Peru', 'Argentina', 'Bolivia', 'Uruguay', 'Brasil', 'Chile'], "Idioma oficial": ['EspaÃ±ol', 'EspaÃ±ol', 'EspaÃ±ol', 'EspaÃ±ol', 'Portugues', 'EspaÃ±ol']}
paises_latam = pd.DataFrame(datos)

print(paises_latam)
```
ğŸ›‘ Alerta: los valores asociados a las claves del diccionario deben ser listas del mismo tamaÃ±o

`df` es el nombre gÃ©nerico para designar DataFrame y es el nombre que utilizaremos de ahora en mÃ¡s para mayor simplicidad.


Otra forma muy usual de generar DataFrames es mediante la lectura de **archivos estructurados**. Existen muchas formas de cargar/leer informaciÃ³n desde archivos la informaciÃ³n desde archivos pero en general la diferencia radica principalmente en los parÃ¡metros por defecto que toman para definir las columnas. Por ejemplo: 

- El caracter de separaciÃ³n de columnas por defecto del mÃ©todo `read_cvs` es una coma (',') 
- El caracter de separaciÃ³n de columnas por defecto del mÃ©todo `read_fwf` es una tab ('\t').

```python
import pandas as pd
df = pd.read_csv(path_al_erchivo)
```

>  ğŸ§—â€â™€ï¸ DesafÃ­o I: Estos mÃ©todos aceptan otros parÃ¡metros que merecen la pena ser explorados. AveriguÃ¡ para quÃ© sirven los parÃ¡metro sep, index_col, nrows y header

>  ğŸ§—â€â™€ï¸ DesafÃ­o II: DescargÃ¡ a tu computadora la [tabla](https://datasets.datos.mincyt.gob.ar/dataset/personal-de-ciencia-y-tecnologia/archivo/11dca5bb-9a5f-4da5-b040-28957126be18) de personas que conforman el Ministerio de Ciencia y TecnologÃ­a de Argentina, en formato csv.
>
> CargÃ¡ (lee) la tabla a un DataFrame de Pandas de nombre `personas` Â¿QuÃ© forma te lectura de archivos usarÃ­as? Â¿QuÃ© separaciÃ³n entre columnas posee el archivo? Â¿CÃ³mo te diste cuenta? ğŸ¤”
>

Ya tenemos nuestra tabla cargada, podeÃ©s hacer una previsualizaciÃ³n de los datos haciendo:

```python
personas.head()
```
> Para pensar ğŸ¤”: Â¿CuÃ¡ntas filas se imprimen al hacer head? Â¿QuÃ© sucede si hacemos `personas.head(10)`? Â¡Probalo!

[2. Trabajando con DataFrames](#2-dfs)

Ahora que aprendiste a cargar datos en una `"tabla"` de Pandas, podÃ©s averiguar la informaciÃ³n general de tu tabla haciendo: 

```python
personas.info()
```

Si bien esta informaciÃ³n nos ayuda a saber los nombres de las columnas de nuestra tabla, o el tipo de datos que contiene cada una de ellas, quizÃ¡s una descripciÃ³n mÃ¡s informativa podrÃ­a ser:

```python
personas.describe()
```
> Para pensar ğŸ¤”: Â¿QuÃ© tipo de informaciÃ³n nos brinda el mÃ©todo describe? Â¿Tienen sentido estos cÃ¡lculos para todas las columnas?
>

Podemos acceder a los datos de cada columna haciendo df['nombre de la columna'], en nuestro caso por ejemplo:

``` python
personas[' persona_id']
```

> Para pensar ğŸ¤”: Â¿PodÃ©s imprimir la columna de los `max_dedicacion_horaria_docente_id` de nuestra tabla? Â¿CÃ³mo calcularÃ­as el promedio de esta columna?

QuizÃ¡s nos resulte Ãºtil acceder, no a todos los datos de una columna, sino a un dato de una celda en particular. Para ello podemos utilizar _iloc_:

```python
df.loc[fila, columna] 
```
esto devuelve el elemento que se encuentra en la fila con nombre fila y la columna de con nombre columna del DataFrame df. ProbÃ¡ el siguiente cÃ³digo:

```python
personas.loc[2, 'persona_id']
```

> Para pensar ğŸ¤”: Â¿QuÃ© resultado obtuviste? Â¿Por quÃ©? Â¿CÃ³mo obtendrÃ­as la edad de esa persona?

Podemos acceder los datos de una columna del DataFrame como una lista mediante el mÃ©todo _tolist()_:

``` python
df['columna'].tolist()
```

>  ğŸ§—â€â™€ï¸ DesafÃ­o IV: Extrae la columna `seniority_level` y contÃ¡ cuÃ¡ntas personas tenÃ­an expertice nivel B, C y D

Seguramente tu resulaciÃ³n del _DesafÃ­o IV_ implicÃ³ hacer un _bucle for_ y un if, lo cual parece a priori un tanto engorroso. Para evitarnos tantas lineas de cÃ³digo, podemos hacer uso de los mÃ©todos _groupby()_ y _count()_, que nos permiten contar sobre una columna la frecuencia de un dato/evento en particular. EjecutÃ¡ las siguientes lineas a ver quÃ© pasa:

```python
personas["seniority_level"].count()

personas.groupby("seniority_level").count()

personas.groupby("seniority_level")[["persona_id"]].count()
```

> ğŸ§—â€â™€ï¸ DesafÃ­o V: Â¿QuÃ© resultados obtuviste en cada caso? ExplicÃ¡ quÃ© hace cada linea de cÃ³digo

Podemos operar con las columnas con los mismo operadores relacionales y matemÃ¡ticos que ya hemos visto:

``` python
personas['edad'] * 2
personas['edad'] + 2
personas['edad'] > 2  
```          
> Para pensar ğŸ¤”: Â¿QuÃ© resultado nos darÃ­a en cada caso? 

Pero los operadores tambien nos sirven tambiÃ©n para filtrar nuestro DataFrame:

``` python
personas[personas['edad'] < 35 ]
```         

> ğŸ§—â€â™€ï¸ DesafÃ­o V: ContÃ¡ cuÃ¡ntas personas de 30 aÃ±os ingresaron al ministerio en 2011 Â¿CuÃ¡ntas formas de hacer este cÃ¡lculo se te ocurren?

Ahora vamos a ver cÃ³mo podemos incorporar mÃ¡s informaciÃ³n a nuestro DataFrame. En la pÃ¡gina del ministerio podÃ©s encontrar las tablas que pueblas la tabla general...veamos por ejemplo la tabla de [categorÃ­a de conicet](https://datasets.datos.mincyt.gob.ar/dataset/personal-de-ciencia-y-tecnologia/archivo/c72c9f88-d9ef-4349-bb20-5c9a1aca5d67)

> ğŸ§—â€â™€ï¸ DesafÃ­o VI: Descargala en formato csv y cargala en un nuevo DataFrame de nombre `categorias`
> ğŸ§—â€â™€ï¸ DesafÃ­o VII: IdentificÃ¡ si existen columnas en comÃºn con el DataFrame grande

Supongamos que ahora queremos poder realizar anÃ¡lisis de nuestros datos filtrando por categoria de conicet, en este caso podemos combinar las dos tablas, de modo de saber quÃ© valos de `categoria_conicet_id` se corresponde con cada categoria de conicet. Probemos haciendo:

``` python
personas_cat = pd.merge(personas, categorias, on='categoria_conicet_id')
```

> Para pensar ğŸ¤”: Â¿QuÃ© datos tiene df3? Â¿QuÃ© hace el mÃ©todo merge? 

Probemos ahora el mÃ©todo _concat()_:
``` python
personas_cat = pd.conact([personas, categorias])
```
> Para pensar ğŸ¤”: Â¿QuÃ© datos tiene df3? Â¿QuÃ© hace el mÃ©todo _concat()_ y quÃ© diferencia tiene con hacer _merge()_? 

[3. MÃ©todos de los DataFrames](#3-metodos)

Veamos un resumen de los mÃ©todos que podÃ©s encontrar en Pandas para trabajar con DataFrames: 

| Lectura/carga de datos | Limpieza de los datos | Estdistica de los datos |
|-------------	|----------	|---	|
| pd.read_csv() | pd.head() | pd.describe() |
| pd.read_table() | pd.fillna() |df.sample()|
| pd.read_excel() | pd.dropna() | pd.mean() |
| pd.read_sql() | pd.sort_values() | pd.median() |
| pd.read_json() | pd.groupby() | pd.std() |
| pd.to_csv() |pd.apply() | pd.min() |
| pd.DataFrame() | pd.append() | pd.max() |
| pd.concat() | pd.rename()  | pd.count() |
| pd.Series() | pd.set_index() | pd.corr() |
| pd.DataFrame.from_dict() |  pd.tail() | pd.hist() |


>
>  ğŸ§—â€â™€ï¸ DesafÃ­o III: averiguÃ¡ para quÃ© sirve cada uno de los mÃ©todos y quÃ© parÃ¡metros podÃ©s pasarseles. Â¡Esta informaciÃ³n nos serÃ¡ Ãºtil para mÃ¡s adelante!
>

Ahora que conocemos algunas de los mÃ©todos que nos permiten trabajar con DataFrames, veamos como cÃ³mo [trabajar los datos](https://github.com/flbulgarelli/recursos-python/blob/master/2_Ciencia_de_datos_pandas/Analisis_de_datos_con_pandas.md) ğŸ¤“